{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ConvLayer2D:\n",
    "   \n",
    "    '''\n",
    "   \n",
    "    INPUT DIMS: (B, C, H, W), only suitable for B = 1 (1 sample)\n",
    "    OUTPUT DIMS: (C, H, W) | NO BATCH DIMENSION FOR NOW\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, seed = None):\n",
    "        self.seed = seed\n",
    "        self._set_seed() \n",
    "        \n",
    "    def forward(self, X, output_channels, kernel_size, padding = 0, stride = 1, dilation_rate = 1):\n",
    "        self.padding = padding\n",
    "        self.X = self._pad(X)\n",
    "        self.output_channels = output_channels\n",
    "        self.kernel_size = kernel_size # tuple to specify height and width, otherwise if int will be nxn where n = kernel_size\n",
    "        self.stride = stride\n",
    "        self.dilation_rate = dilation_rate\n",
    "        \n",
    "        Y = self._forward_util()\n",
    "        \n",
    "        return Y\n",
    "        \n",
    "    def _forward_util(self):\n",
    "       \n",
    "        self._create_kernel()\n",
    "        \n",
    "        output_height = int(((self.X.shape[2] - self.kernel.shape[2]) / self.stride) + 1)\n",
    "        output_width = int(((self.X.shape[3] - self.kernel.shape[3]) / self.stride) + 1)\n",
    "    \n",
    "        Y = np.zeros(shape = (self.output_channels, output_height, output_width)) \n",
    "    \n",
    "        for out_ch in range(Y.shape[0]): # for each output channel\n",
    "            for m in range(Y.shape[1]): # for each row idx in a given channel\n",
    "                for n in range(Y.shape[2]): # for each column idx in a given channel\n",
    "                    for in_ch in range(self.X.shape[1]): # for each input channel in X\n",
    "                        n_slice_idx = n * self.stride # position of kernel on the feature map, (top left of kernel)\n",
    "                        current_slice = self.X[0, in_ch, m:m+self.kernel.shape[2], n_slice_idx:(n_slice_idx + self.kernel.shape[3])]\n",
    "                        conv_out = [] \n",
    "                    \n",
    "                        if self.kernel.shape[0] == 1 and self.X.shape[1] == 1:\n",
    "                            if current_slice.size != self.kernel.size:\n",
    "                                break \n",
    "                        elif self.kernel.shape[0] >= 1 and self.X.shape[1] >= 1:\n",
    "                            if current_slice.size != self.kernel[out_ch, in_ch].size:\n",
    "                                break\n",
    "                        \n",
    "                        for k in range(self.kernel.shape[1]): \n",
    "                            conv_ch = current_slice * self.kernel[out_ch, k]\n",
    "                            conv_out.append(conv_ch)\n",
    "                        \n",
    "                            \n",
    "                        Y[out_ch, m ,n] = np.sum(conv_out)\n",
    "    \n",
    "        print(f\"Input | {self.X.shape}:\\n\\n{self.X}\\n\\n\")\n",
    "        print(f\"Kernel | {self.kernel.shape}:\\n\\n{self.kernel}\\n\\n\")\n",
    "        print(f\"Output | {Y.shape}:\\n\\n{Y}\\n\\n\")\n",
    "\n",
    "        return Y\n",
    "        \n",
    "    def _create_kernel(self):\n",
    "      \n",
    "        if self.dilation_rate != 1: \n",
    "            kernel_mask = np.random.random_sample(size = (self.output_channels, self.X.shape[1], *self.kernel_size)) # create a 4darray, shape: (Output Size, Input Size, Height, Width)\n",
    "            self.kernel = self._dilate_multiple_in_out_ch(kernel_mask) \n",
    "            assert self.kernel.shape[2] <= self.X.shape[2], ValueError('height of kernel cannot be larger than height of input feature map')\n",
    "            assert self.kernel.shape[3] <= self.X.shape[3], ValueError('width of kernel cannot be larger than width of input feature map')\n",
    "\n",
    "        elif self.dilation_rate == 1:\n",
    "            self.kernel = np.random.random_sample(size = (self._output_channels, self.X.shape[1], *self.kernel_size))\n",
    "\n",
    "    def _dilate_multiple_in_out_ch(self, kernel_mask):\n",
    "       \n",
    "        '''\n",
    "        Dilatation for Kernels of multiple input and output channels\n",
    "        \n",
    "        kernel_mask | (Out, In, H, W) \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        if kernel_mask.shape[2] == 1 and kernel_mask.shape[3] == 1:\n",
    "            return kernel_mask\n",
    "\n",
    "        k_h = kernel_mask.shape[2] * self.dilation_rate - (self.dilation_rate - 1)\n",
    "        k_w = kernel_mask.shape[3] * self.dilation_rate - (self.dilation_rate - 1)\n",
    "        \n",
    "        out_kernel = np.zeros(shape = (kernel_mask.shape[0], kernel_mask.shape[1], k_h, k_w))       \n",
    "        \n",
    "        dilation_rate = self.dilation_rate - 1\n",
    "        \n",
    "        for out_ch in range(kernel_mask.shape[0]):\n",
    "            for in_ch in range(kernel_mask.shape[1]):\n",
    "                for row in range(kernel_mask.shape[2]):\n",
    "                    \n",
    "                    m = 0 # initializing row indices\n",
    "                    \n",
    "                    k_matrix_m = kernel_mask[out_ch, in_ch, row] # choosing the mth row\n",
    "                    \n",
    "                    while m < len(k_matrix_m): # while we aren't at the last position of a given row of the kernel\n",
    "                        if k_matrix_m[m] != 0:\n",
    "                            k_matrix_m = np.concatenate((k_matrix_m[:m +1], [0 for _ in range(dilation_rate)], k_matrix_m[m+1:]))\n",
    "                            m += dilation_rate\n",
    "                        \n",
    "                        m += +1\n",
    "                        \n",
    "                        if m == (len(k_matrix_m) - 1):\n",
    "                            out_kernel[out_ch, in_ch, (row * (dilation_rate + 1))] = k_matrix_m\n",
    "                            break\n",
    "        return out_kernel\n",
    "         \n",
    "    def _pad(self, X):\n",
    "        pad_width = ((0, 0), (0, 0), (self.padding, self.padding), (self.padding, self.padding))\n",
    "        X = np.pad(X, pad_width = pad_width)\n",
    "        return X \n",
    "          \n",
    "    def _set_seed(self):\n",
    "        if self.seed is not None:\n",
    "            np.random.seed(self.seed)\n",
    "            \n",
    "    @property\n",
    "    def dilation_rate(self):\n",
    "        return self._dilation_rate\n",
    "    \n",
    "    @dilation_rate.setter\n",
    "    def dilation_rate(self, dilation_rate):\n",
    "        assert dilation_rate >= 1, ValueError('Dilation cannot be less than 1 for the Kernel!')\n",
    "        self._dilation_rate = dilation_rate\n",
    "    \n",
    "    @property\n",
    "    def output_channels(self):\n",
    "        return self._output_channels\n",
    "    \n",
    "    @output_channels.setter\n",
    "    def output_channels(self, output_channels):\n",
    "        assert output_channels >= 1, ValueError('Output Channels cannot be less than 1!')\n",
    "        self._output_channels = output_channels\n",
    "        \n",
    "    @property\n",
    "    def kernel_size(self):\n",
    "        return self._kernel_size     \n",
    "   \n",
    "    @kernel_size.setter\n",
    "    def kernel_size(self, kernel_size):\n",
    "        if isinstance(kernel_size, int):\n",
    "            self._kernel_size = (kernel_size, kernel_size)\n",
    "        elif kernel_size[1] == 1 or kernel_size[0] == 1:\n",
    "            raise ValueError('Kernel cannot be 1-Dimensional for a 2D convolution!')\n",
    "        else:\n",
    "            assert self.X.shape[2] >= self._kernel_size[2], ValueError('Kernel height cannot be greater than height of input tensor!')\n",
    "            assert self.X.shape[3] >= self._kernel_size[3], ValueError('Kernel width cannot be greater than height of input tensor!')\n",
    "            self._kernel_size = kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input | (1, 2, 5, 5):\n",
      "\n",
      "[[[[0.417022   0.72032449 0.00011437 0.30233257 0.14675589]\n",
      "   [0.09233859 0.18626021 0.34556073 0.39676747 0.53881673]\n",
      "   [0.41919451 0.6852195  0.20445225 0.87811744 0.02738759]\n",
      "   [0.67046751 0.4173048  0.55868983 0.14038694 0.19810149]\n",
      "   [0.80074457 0.96826158 0.31342418 0.69232262 0.87638915]]\n",
      "\n",
      "  [[0.89460666 0.08504421 0.03905478 0.16983042 0.8781425 ]\n",
      "   [0.09834683 0.42110763 0.95788953 0.53316528 0.69187711]\n",
      "   [0.31551563 0.68650093 0.83462567 0.01828828 0.75014431]\n",
      "   [0.98886109 0.74816565 0.28044399 0.78927933 0.10322601]\n",
      "   [0.44789353 0.9085955  0.29361415 0.28777534 0.13002857]]]]\n",
      "\n",
      "\n",
      "Kernel | (1, 2, 4, 4):\n",
      "\n",
      "[[[[0.417022   0.         0.         0.72032449]\n",
      "   [0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.        ]\n",
      "   [0.00011437 0.         0.         0.30233257]]\n",
      "\n",
      "  [[0.14675589 0.         0.         0.09233859]\n",
      "   [0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.        ]\n",
      "   [0.18626021 0.         0.         0.34556073]]]]\n",
      "\n",
      "\n",
      "Output | (1, 2, 2):\n",
      "\n",
      "[[[1.33804174 0.96789855]\n",
      "  [0.7586532  1.05325791]]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "x = np.random.random_sample(size = (1, 2, 5, 5))\n",
    "\n",
    "model = ConvLayer2D(seed = 1)\n",
    "\n",
    "Y = model.forward(x, output_channels=1, kernel_size = 2, padding = 0, stride = 1, dilation_rate = 3) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
